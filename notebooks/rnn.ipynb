{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(446)\n",
    "\n",
    "class RNN(eqx.Module): \n",
    "    hidden_dim: int\n",
    "    Wh: eqx.nn.Linear\n",
    "    Wx: eqx.nn.Linear\n",
    "    Wy: eqx.nn.Linear\n",
    "    act: callable\n",
    "    \n",
    "    # TODO: check bias \n",
    "    def __init__(self, input_dim=2, hidden_dim=2, output_dim=1):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.Wh = eqx.nn.Linear(hidden_dim, hidden_dim, key=key)\n",
    "        self.Wx = eqx.nn.Linear(input_dim, hidden_dim, key=key)\n",
    "        self.Wy = eqx.nn.Linear(hidden_dim, output_dim, key=key)\n",
    "        self.act = jax.nn.sigmoid\n",
    "\n",
    "    def __call__(self, x): \n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # hidden = torch.nn.Parameter(torch.zeros(batch_size, self.hidden_dim))\n",
    "        hidden = jnp.zeros((self.hidden_dim, batch_size))\n",
    "        outs = []\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            # print(self.Wh(hidden).shape)\n",
    "            print(hidden.shape)\n",
    "            hidden = self.act(self.Wh(hidden) + self.Wx(x[:,i,:]))\n",
    "            out = self.Wy(hidden)\n",
    "            outs.append(out)\n",
    "        \n",
    "        # output shape = (batch_size, sequence length, output dimension)\n",
    "        # return torch.stack(outs).permute(1,0,2)\n",
    "        stacked = jnp.stack(outs, axis=1)\n",
    "        return jnp.transpose(stacked, (1,0,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  hidden_dim=2,\n",
      "  Wh=Linear(\n",
      "    weight=f32[2,2],\n",
      "    bias=f32[2],\n",
      "    in_features=2,\n",
      "    out_features=2,\n",
      "    use_bias=True\n",
      "  ),\n",
      "  Wx=Linear(\n",
      "    weight=f32[2,2],\n",
      "    bias=f32[2],\n",
      "    in_features=2,\n",
      "    out_features=2,\n",
      "    use_bias=True\n",
      "  ),\n",
      "  Wy=Linear(\n",
      "    weight=f32[1,2],\n",
      "    bias=f32[1],\n",
      "    in_features=2,\n",
      "    out_features=1,\n",
      "    use_bias=True\n",
      "  ),\n",
      "  act=<wrapped function sigmoid>\n",
      ")\n",
      "(128, 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (2,) and (128,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(key, (batch_size, seq_len, input_dim))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_len):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# print(self.Wh(hidden).shape)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(hidden\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 28\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWx(x[:,i,:]))\n\u001b[1;32m     29\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWy(hidden)\n\u001b[1;32m     30\u001b[0m     outs\u001b[38;5;241m.\u001b[39mappend(out)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pebble/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pebble/lib/python3.11/site-packages/equinox/nn/_linear.py:102\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx must have scalar shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m     x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mbroadcast_to(x, (\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m--> 102\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pebble/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:271\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    269\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pebble/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:3359\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3357\u001b[0m a \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m   3358\u001b[0m b \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m-> 3359\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m  \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_is_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m result \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n\u001b[1;32m   3363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pebble/lib/python3.11/site-packages/jax/_src/lax/lax.py:2580\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2578\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2579\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2580\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (2,) and (128,)."
     ]
    }
   ],
   "source": [
    "model = RNN(input_dim=2, hidden_dim=2, output_dim=1)\n",
    "\n",
    "batch_size = 128\n",
    "seq_len = 10\n",
    "input_dim = 2\n",
    "x = jax.random.normal(key, (batch_size, seq_len, input_dim))\n",
    "print(model)\n",
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pebble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
